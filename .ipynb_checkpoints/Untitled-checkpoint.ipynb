{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "330445bb-53bb-460b-a1dd-f7edf94844e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thuật toán\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "class LogisticRegression():\n",
    "    def __init__(self, X, y , X_valid, y_valid, lr,epochs, reg = False,useoptimizer = False,ismultiClass = False):\n",
    "        self.X,self.y,  self.X_valid,self.y_valid,self.lr ,self.epochs,self.reg,self.useoptimizer, self.ismultiClass= X, y , X_valid, y_valid, lr, epochs, reg, useoptimizer,ismultiClass\n",
    "        if(not ismultiClass):            \n",
    "            self.optim = GradientDesent( X, y , X_valid, y_valid, lr,epochs, reg,useoptimizer, self.sigmoid)\n",
    "   \n",
    "    def sigmoid(self, z):    \n",
    "        return 1/(1+np.exp(-z))  \n",
    "    \n",
    "    def fit(self):\n",
    "        if(self.ismultiClass):\n",
    "            w=self.fitMulti()\n",
    "            return w\n",
    "        else:\n",
    "            w = self.optim.optimize()\n",
    "            h = self.sigmoid(np.dot(self.X, w))\n",
    "            h_valid = self.sigmoid(np.dot(self.X_valid, w))\n",
    "            train_preds = [1 if i > 0.5 else 0 for i in h]\n",
    "            val_preds = [1 if i > 0.5 else 0 for i in h_valid]\n",
    "            return w\n",
    "            train_accuracy =  accuracy_score(self.y , train_preds)\n",
    "            val_accuracy =  accuracy_score(self.y_valid , val_preds)\n",
    "\n",
    "            print(f'Train Accuracy: {train_accuracy} Val Accuracy: {val_accuracy}')   \n",
    "        \n",
    "        \n",
    "    def fitMulti(self):\n",
    "        labelCount = len(np.unique(self.y))\n",
    "        #print(f'Total label Count: {labelCount}') \n",
    "        w = np.zeros((labelCount, self.X.shape[1]))\n",
    "        for i in range(1, labelCount+1):\n",
    "            #print(f'Train LG for class : {i}')\n",
    "            y_change = np.array([1 if i == label else 0 for label in self.y])\n",
    "            y_valid_change = np.array([1 if i == label else 0 for label in self.y_valid])            \n",
    "            optim = GradientDesent( self.X, y_change , self.X_valid, y_valid_change, self.lr, self.epochs, self.reg, self.useoptimizer, self.sigmoid)\n",
    "            w[i-1:] = optim.optimize()                     \n",
    "            \n",
    "            \n",
    "        train_preds = np.argmax(self.sigmoid(np.dot(self.X, w.T)) ,axis = 1) + 1\n",
    "        val_preds = np.argmax(self.sigmoid(np.dot(self.X_valid, w.T)) ,axis = 1) + 1\n",
    "        return w         \n",
    "        \n",
    "        train_accuracy =  accuracy_score(self.y , train_preds)\n",
    "        val_accuracy =  accuracy_score(self.y_valid , val_preds)        \n",
    "        print(f'Train Accuracy: {train_accuracy} Val Accuracy: {val_accuracy}')\n",
    "\n",
    "    def dudoan(self,dulieu):\n",
    "        w=self.fit()\n",
    "        ketqua=np.argmax(self.sigmoid(np.dot(dulieu, w.T)) ,axis = 1) + 1\n",
    "        return ketqua\n",
    "\n",
    "import scipy.optimize as opt\n",
    "class GradientDesent():\n",
    "    \n",
    "    def __init__(self, X, y , X_valid, y_valid, lr, epochs, reg = False, useoptimizer = False, activate_fn = None):\n",
    "        self.X,self.y,  self.X_valid,self.y_valid,self.lr ,self.epochs, self.reg, self.useoptimizer, self.activate_fn  = X, y , X_valid, y_valid, lr,epochs, reg,useoptimizer,activate_fn\n",
    "            \n",
    "    def optimize(self):\n",
    "        w = np.zeros(self.X.shape[1])\n",
    "              \n",
    "        \n",
    "        if(self.useoptimizer):\n",
    "            result = opt.fmin_tnc(func=self.cost, x0=w, fprime=self.gradient,args=(self.X, self.y)) \n",
    "            train_loss= self.cost(result[0], self.X, self.y)\n",
    "            val_loss = self.cost(result[0], self.X_valid, self.y_valid)  \n",
    "            #print(f'Runned Spicy Optimizer > Train Loss: {train_loss} Val Loss: {val_loss}')          \n",
    "            return result[0]             \n",
    "            \n",
    "        train_cost = np.zeros(self.epochs)\n",
    "        val_cost = np.zeros(self.epochs)      \n",
    "\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            grad = self.gradient(w, self.X, self.y)\n",
    "            w = np.subtract(w , np.multiply(grad , self.lr))\n",
    "            train_loss= self.cost(w, self.X, self.y)\n",
    "            val_loss = self.cost(w, self.X_valid, self.y_valid)         \n",
    "            train_cost[i] = train_loss\n",
    "            val_cost[i] = val_loss\n",
    "            #print(f'Epochs: {i} Train Loss: {train_loss} Val Loss: {val_loss}')   \n",
    "            \n",
    "        \n",
    "        return w\n",
    "        # hàm mất mát\n",
    "    def cost(self,w, X, y):\n",
    "        h = np.dot(X, w)\n",
    "        m = len(X)       \n",
    "        if(self.activate_fn != None):  h = self.activate_fn(h)\n",
    "        \n",
    "        loss= (np.dot(-y, np.log(h))) - (np.dot(1-y, np.log(1-h)))\n",
    "        loss = np.sum(loss)/m\n",
    "        \n",
    "        if(self.reg):           \n",
    "            loss = loss + ((self.lr/2*m) * np.sum(np.power(w,2)))\n",
    "        return loss\n",
    "            \n",
    "    def gradient(self,w,X, y):\n",
    "        h = np.dot(X, w)      \n",
    "        if(self.activate_fn != None):  h = self.activate_fn(h)     \n",
    "        m = len(X)\n",
    "        loss= h - y\n",
    "        gradient = np.dot(X.T,loss)/m\n",
    "        if(self.reg): gradient = gradient + np.dot((self.lr/m), w)      \n",
    "        return gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d8565f-b5dd-42f6-b21e-775a5521e824",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatted Date              39627\n",
      "Summary                         0\n",
      "Precip Type                   364\n",
      "Temperature (C)                 0\n",
      "Apparent Temperature (C)        0\n",
      "Humidity                        0\n",
      "Wind Speed (km/h)               0\n",
      "Wind Bearing (degrees)          0\n",
      "Visibility (km)                 0\n",
      "Loud Cover                      0\n",
      "Pressure (millibars)            0\n",
      "Daily Summary               39627\n",
      "dtype: int64\n",
      "rain    32636\n",
      "snow     6627\n",
      "Name: Precip Type, dtype: int64\n",
      "   Summary  Precip Type  Temperature (C)  Apparent Temperature (C)  Humidity  \\\n",
      "0        1            0        10.911111                 10.911111      0.86   \n",
      "1        1            0         8.800000                  5.294444      0.99   \n",
      "2        1            0         8.200000                  5.072222      0.96   \n",
      "3        1            0         8.177778                  4.372222      0.93   \n",
      "4        1            0         5.211111                  5.211111      0.92   \n",
      "\n",
      "   Wind Speed (km/h)  Visibility (km)  Pressure (millibars)  \n",
      "0            22.3951           2.6565               1004.61  \n",
      "1            26.5006           2.6565               1004.99  \n",
      "2            20.4470           3.1073               1004.80  \n",
      "3            27.8691           3.2039               1004.89  \n",
      "4             4.7656           1.2236               1013.40  \n",
      "Number of classes: 4\n",
      "[0 1 2 3]\n",
      "                           Summary  Precip Type  Temperature (C)  \\\n",
      "Summary                   1.000000    -0.064982        -0.043679   \n",
      "Precip Type              -0.064982     1.000000        -0.616639   \n",
      "Temperature (C)          -0.043679    -0.616639         1.000000   \n",
      "Apparent Temperature (C) -0.059106    -0.615049         0.991178   \n",
      "Humidity                  0.123301     0.221579        -0.575249   \n",
      "Wind Speed (km/h)         0.284833    -0.077782         0.059687   \n",
      "Visibility (km)           0.025644    -0.331981         0.484698   \n",
      "Pressure (millibars)      0.149849     0.014593        -0.032440   \n",
      "\n",
      "                          Apparent Temperature (C)  Humidity  \\\n",
      "Summary                                  -0.059106  0.123301   \n",
      "Precip Type                              -0.615049  0.221579   \n",
      "Temperature (C)                           0.991178 -0.575249   \n",
      "Apparent Temperature (C)                  1.000000 -0.545518   \n",
      "Humidity                                 -0.545518  1.000000   \n",
      "Wind Speed (km/h)                        -0.023102 -0.237119   \n",
      "Visibility (km)                           0.465800 -0.505356   \n",
      "Pressure (millibars)                     -0.023876  0.067977   \n",
      "\n",
      "                          Wind Speed (km/h)  Visibility (km)  \\\n",
      "Summary                            0.284833         0.025644   \n",
      "Precip Type                       -0.077782        -0.331981   \n",
      "Temperature (C)                    0.059687         0.484698   \n",
      "Apparent Temperature (C)          -0.023102         0.465800   \n",
      "Humidity                          -0.237119        -0.505356   \n",
      "Wind Speed (km/h)                  1.000000         0.164870   \n",
      "Visibility (km)                    0.164870         1.000000   \n",
      "Pressure (millibars)              -0.052082         0.052481   \n",
      "\n",
      "                          Pressure (millibars)  \n",
      "Summary                               0.149849  \n",
      "Precip Type                           0.014593  \n",
      "Temperature (C)                      -0.032440  \n",
      "Apparent Temperature (C)             -0.023876  \n",
      "Humidity                              0.067977  \n",
      "Wind Speed (km/h)                    -0.052082  \n",
      "Visibility (km)                       0.052481  \n",
      "Pressure (millibars)                  1.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14664\\4172205941.py:93: RuntimeWarning: divide by zero encountered in log\n",
      "  loss= (np.dot(-y, np.log(h))) - (np.dot(1-y, np.log(1-h)))\n",
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.44201842276916803\n",
      "recall 0.5717898492026894\n",
      "accuracy  0.5314155942467828\n",
      "F1 score 0.49655804082812105\n",
      "precision:  0.5629628221866565\n",
      "recall 0.578591539803554\n",
      "accuracy  0.5456304146690217\n",
      "F1 score 0.5679062953364263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Trainning\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import copy\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import *\n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Import label encoder\n",
    "from sklearn import preprocessing\n",
    "dataset = pd.read_csv(r'weatherHistory_Chon4nhan.csv')\n",
    "X = dataset.iloc[:, 1:].values\n",
    "# print(X[:3])\n",
    "row=len(X)\n",
    "col=len(X[0])\n",
    "attribute = ['Formatted Date', 'Summary', 'Precip Type', 'Temperature (C)', 'Apparent Temperature (C)', 'Humidity', 'Wind Speed (km/h)', 'Wind Bearing (degrees)', 'Visibility (km)', 'Loud Cover', 'Pressure (millibars)', 'Daily Summary']\n",
    "df=pd.DataFrame(dataset, columns = attribute)\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "  \n",
    "\n",
    "print(df.isnull().sum())\n",
    "print(df['Precip Type'].value_counts())\n",
    "\n",
    "df['Precip Type'].fillna(method='ffill',inplace=True,axis=0)\n",
    "df['Precip Type']= label_encoder.fit_transform(df['Precip Type'])\n",
    "\n",
    "\n",
    "df['Summary']= label_encoder.fit_transform(df['Summary'])\n",
    "  \n",
    "# df['Summary'].unique()\n",
    "\n",
    "df=df.drop(labels='Formatted Date', axis=1)\n",
    "df=df.drop(labels='Loud Cover', axis=1)\n",
    "df=df.drop(labels='Daily Summary', axis=1)\n",
    "# df=df.drop(labels='Precip Type', axis=1)\n",
    "#df=df.drop(labels='Wind Speed (km/h)', axis=1)--\n",
    "df=df.drop(labels='Wind Bearing (degrees)', axis=1)\n",
    "# df=df.drop(labels='Humidity', axis=1)\n",
    "# df=df.drop(labels='Visibility (km)', axis=1)\n",
    "# df=df.drop(labels='Temperature (C)', axis=1)\n",
    "# df=df.drop(labels='Apparent Temperature (C)', axis=1)\n",
    "# df=df.drop(labels='Pressure (millibars)', axis=1)\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "print ('Number of classes: %d' %len(np.unique(df['Summary'])))\n",
    "print(np.unique(df['Summary']))\n",
    "\n",
    "# print ('Number of classes: %d' %len(np.unique(df['Daily Summary'])))\n",
    "# print(np.unique(df['Daily Summary']))\n",
    "\n",
    "corr=df.corr()\n",
    "print(corr)\n",
    "\n",
    "# corList,a,dic=[],0,{}\n",
    "# for i in df.feature_names:\n",
    "#     dic[i]=abs(corr[\"Summary\"][a])\n",
    "#     corList.append(abs(corr[\"Summary\"][a]))\n",
    "#     a+=1\n",
    "\n",
    "\n",
    "x=df.drop(labels=\"Summary\",axis=1)\n",
    "y=df[\"Summary\"]\n",
    "\n",
    "\n",
    "#Lấy code từ đây nhá\n",
    "#X = np.insert(x.to_numpy(), 0,  np.ones(x.to_numpy().shape[0]), axis =1)\n",
    "train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.3, train_size=0.7)\n",
    "\n",
    "X_train=np.insert(train_x.to_numpy(), 0,  np.ones(train_x.to_numpy().shape[0]), axis =1)\n",
    "y_train=train_y.to_numpy()\n",
    "X_valid=np.insert(test_x.to_numpy(), 0,  np.ones(test_x.to_numpy().shape[0]), axis =1)\n",
    "y_valid=test_y.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "model = LogisticRegression(X_train, y_train,X_valid,y_valid,  lr = 0.001, epochs =100,useoptimizer=True,ismultiClass=True)\n",
    "kq=model.dudoan(X_valid)\n",
    "\n",
    "precision=precision_score(y_valid,kq, average='macro')\n",
    "recall=recall_score(y_valid,kq, average='macro')\n",
    "accuracyScore = accuracy_score(y_valid,kq)\n",
    "f1Score= f1_score(y_valid,kq, average='macro')\n",
    "\n",
    "\n",
    "print('precision: ', precision)\n",
    "print('recall', recall)\n",
    "print('accuracy ',accuracyScore)\n",
    "print('F1 score', f1Score)\n",
    "\n",
    "\n",
    "clf = linear_model.LogisticRegression()\n",
    "clf.fit(train_x, train_y)\n",
    "predicted_y=clf.predict(test_x)\n",
    "\n",
    "precision=precision_score(test_y,predicted_y, average='macro')\n",
    "recall=recall_score(test_y,predicted_y, average='macro')\n",
    "accuracyScore = accuracy_score(test_y,predicted_y)\n",
    "f1Score= f1_score(test_y,predicted_y, average='macro')\n",
    "\n",
    "\n",
    "print('precision: ', precision)\n",
    "print('recall', recall)\n",
    "print('accuracy ',accuracyScore)\n",
    "print('F1 score', f1Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9ba432-fc6c-433e-90dc-13b71fdff4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0a8edf-0e98-4a5b-9f03-f7719c3b0fec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
